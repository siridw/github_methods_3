---
title: "practical_exercise_2, Methods 3, 2021, autumn semester"
author: "Sirid Wihlborg"
date: "29/09/21"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 1: Using mixed effects modelling to model hierarchical data
In this assignment we will be investigating the _politeness_ dataset of Winter and Grawunder (2012) and apply basic methods of multilevel modelling. 

## Dataset
The dataset has been shared on GitHub, so make sure that the csv-file is on your current path. Otherwise you can supply the full path.

```{r}
politeness <- read.csv('politeness.csv') ## read in data
politeness <- na.omit(politeness)
pacman::p_load(tidyverse, lme4, car,lmerTest)
```

# Exercises and objectives
The objectives of the exercises of this assignment are:  
1) Learning to recognize hierarchical structures within datasets and describing them  
2) Creating simple multilevel models and assessing their fitness  
3) Write up a report about the findings of the study  

REMEMBER: In your report, make sure to include code that can reproduce the answers requested in the exercises below  
REMEMBER: This assignment will be part of your final portfolio

## Exercise 1 - describing the dataset and making some initial plots

1) Describe the dataset, such that someone who happened upon this dataset could understand the variables and what they contain  
    i. Also consider whether any of the variables in _politeness_ should be encoded as factors or have the factor encoding removed. Hint: ```?factor```  
    

__Explaining the data-set__

The experiment that the data relies set out to investigate whether our pitch changes depending on if we are in a formal or informal setting. The experiment was done in Korea. 
Each participant went through two conditions (column: attitude) either an informal or formal. They had to read out loud a pre-printed sentence and this recording was analysed in terms of pitch so the variable contains the mean pitch in Hz pr sentence (column: f0mn). Besides these variable we have a variable expressing gender (F = Female, M = Male), a variable where the scenario is given (scenario: an integer 1:7).

 
```{r}
politeness$gender <- as.factor(politeness$gender)
politeness$scenario <- as.factor(politeness$scenario)
```



2) Create a new data frame that just contains the subject _F1_ and run two linear models; one that expresses _f0mn_ as dependent on _scenario_ as an integer; and one that expresses _f0mn_ as dependent on _scenario_ encoded as a factor  

```{r}
sub_poli <- politeness[which(politeness$subject == "F1"),]

lm1 <- lm(f0mn~as.factor(scenario), data = sub_poli)
lm2 <- lm(f0mn~as.integer(scenario), data = sub_poli)
```
    
    i. Include the model matrices, $X$ from the General Linear Model, for these two models in your report and describe the different interpretations of _scenario_ that these entail
    ii. Which coding of _scenario_, as a factor or not, is more fitting?


```{r}
print(model.matrix(lm1)) # print design matrix for factor model
print(model.matrix(lm2)) # print design matrix for integer model
```

Having scenario as an integer will make the model mistakenly interpret each scenario as 7 numerical values, where there are relationship between the number which also implies that we hypothetically could "predict" the pitch of a scenario 8 from the pitch in scenario 7, which doesn't make sense. Therefor it makes sense to treat scenario as a factor, having 7 different independent scenario. 

I can't really explain why the design matrices look the way they do, maybe you could elaborate on this in class :) 


3) Make a plot that includes a subplot for each subject that has _scenario_ on the x-axis and _f0mn_ on the y-axis and where points are colour coded according to _attitude_
    i. Describe the differences between subjects

```{r}
ggplot(data = politeness, aes(x = scenario, y = f0mn, color = attitude)) +
  geom_point() + 
  facet_wrap(~subject)
```
We see that the different participants have clearly different baselines meaning that they speak with generally different pitch, which makes good sense. 

    
## Exercise 2  - comparison of models

For this part, make sure to have `lme4` installed.  
You can install it using `install.packages("lme4")` and load it using `library(lme4)`  
`lmer` is used for multilevel modelling

```{r, eval=FALSE}
#mixed.model <- lmer(formula=..., data=...)
#example.formula <- formula(dep.variable ~ first.level.variable + (1 | second.level.variable))
```

1) Build four models and do some comparisons
    i. a single level model that models _f0mn_ as dependent on _gender_
    ii. a two-level model that adds a second level on top of i. where unique intercepts are modelled for each _scenario_
    iii. a two-level model that only has _subject_ as an intercept 
    iv. a two-level model that models intercepts for both _scenario_ and _subject_
```{r}
m1 <- lm(f0mn ~ gender, data = politeness)
m2 <- lmerTest::lmer(f0mn ~ gender + (1|scenario), data = politeness, REML = FALSE)
m3 <- lmerTest::lmer(f0mn ~ gender + (1|subject), data = politeness, REML = FALSE)
m4 <- lmerTest::lmer(f0mn ~ gender + (1|scenario) + (1|subject), data = politeness, REML = FALSE)
```
    v. which of the models has the lowest residual standard deviation, also compare the Akaike Information Criterion `AIC`?
```{r}
# Finding residual standard deviation 
tibble(sigma(m1), sigma(m2), sigma(m3), sigma(m4))

# Finding AIC
AIC(m1, m2, m3, m4)
```

The fourth model: a two-level model that models intercepts for both _scenario_ and _subject_. This model has the lowest AIC value and lowest residual standard deviation.


    vi. which of the second-level effects explains the most variance?
```{r}
summary(m4)
```


2) Why is our single-level model bad?

Because we have some systemacy in our error term (like subject and gender) so putting these as random effects drastically helps our model to "make sense" of the noise.  

    i. create a new data frame that has three variables, _subject_, _gender_ and _f0mn_, where _f0mn_ is the average of all responses of each subject, i.e. averaging across _attitude_ and_scenario_
  
```{r message=FALSE, warning=FALSE}
politeness2 <- politeness %>% 
  group_by(subject, gender) %>% 
  summarise(mean_pitch = mean(f0mn))

head(politeness2)
```

  
    ii. build a single-level model that models _f0mn_ as dependent on _gender_ using this new dataset
    
```{r}
m5 <- lm(mean_pitch ~ gender, data = politeness2)
```


    iii. make Quantile-Quantile plots, comparing theoretical quantiles to the sample quantiles) using `qqnorm` and `qqline` for the new single-level model and compare it to the old single-level model (from 1).i). Which model's residuals ($\epsilon$) fulfil the assumptions of the General Linear Model better?)
    

```{r}
qqPlot(m1) # Plot using all pitch scores pr. participant 
qqPlot(m5) # Plot using the averaged pitch score pr. participant 
```

We see that the qqplot on the averaged data is in fact more close to being normally distributed. However, this might be an illusion since we don't have a lot of data points so we are for sure more insecure on judging residual normality.

    iv. Also make a quantile-quantile plot for the residuals of the  multilevel model with two intercepts. Does it look alright?  

```{r}
qqPlot(residuals(m4))
```


3) Plotting the two-intercepts model
    i. Create a plot for each subject, (similar to part 3 in Exercise 1), this time also indicating the fitted value for each of the subjects for each for the scenarios (hint use `fixef` to get the "grand effects" for each gender and `ranef` to get the subject- and scenario-specific effects)


```{r}
ggplot(data = politeness, aes(x = scenario, y = f0mn, color = attitude)) +
  geom_point() + 
  geom_point(aes(x = scenario, y = fitted(m4), color = "fitted")) + # adding the fitted values pr. subject pr. scenario
  facet_wrap(~subject)
```

    
## Exercise 3 - now with attitude

1) Carry on with the model with the two unique intercepts fitted (_scenario_ and _subject_).
    i. now build a model that has _attitude_ as a main effect besides _gender_

```{r}
m6 <- lmerTest::lmer(f0mn ~ gender + attitude + (1 | scenario) + (1 | subject), data = politeness, REML = FALSE)
```


    ii. make a separate model that besides the main effects of _attitude_ and _gender_ also include their interaction
    
```{r}
m7 <- lmerTest::lmer(f0mn ~ gender * attitude + (1 | scenario) + (1 | subject), data = politeness, REML = FALSE)
```


    iii. describe what the interaction term in the model says about Korean men's pitch when they are polite relative to Korean women's pitch when they are polite (you don't have to judge whether it is interesting)  

```{r}
fixef(m7)
```


We see that the p-value is way above the threshold (.05) indicating no significant interaction effect on gender and pitch difference. However, had we assumed that the p-value was below .05 we could have concluded: 
The interaction term is positive meaning that men generally lower their pitch *less* when changing to an informal setting. 


2) Compare the three models (1. gender as a main effect; 2. gender and attitude as main effects; 3. gender and attitude as main effects and the interaction between them. For all three models model unique intercepts for _subject_ and _scenario_) using residual variance, residual standard deviation and AIC. 


```{r}
# m4: f0mn ~ gender + (1 | scenario) + (1 | subject)
# m6:  f0mn ~ gender + attitude + (1 | scenario) + (1 | subject)
# m7: f0mn ~ gender * attitude + (1 | scenario) + (1 | subject)

# Finding sum of residual variance
tibble(sum(residuals(m4)^2),
       sum(residuals(m6)^2),
       sum(residuals(m7)^2))


# Finding residual standard deviation 
tibble(sigma(m4), sigma(m6), sigma(m7))

# Finding AIC
AIC(m4, m6, m7)
```


3)  Choose the model that you think describe the data the best - and write a short report on the main findings based on this model. At least include the following:
  i. describe what the dataset consists of  
  ii. what can you conclude about the effect of gender and attitude on pitch (if anything)?  
  iii. motivate why you would include separate intercepts for subjects and scenarios (if you think they should be included)  
  iv. describe the variance components of the second level (if any)  
  v. include a Quantile-Quantile plot of your chosen model  


This paper uses data fronm an experiment by Bodo Winter (2012) set out to investigate whether our pitch changes depending on if we are in a formal or informal setting. The experiment was done in Korea. Each participant went through two conditions (column: attitude) either an informal or formal. They had to read out loud a pre-printed sentence and this recording was analysed in terms of pitch so the variable contains the mean pitch in Hz pr sentence (column: f0mn). 

Generally, when choosing my model I would probably never primarily choose the model given what's describing the data best, but rather what makes sense given my hypothesis and assumption. So, for example if my hypothesis explicitly investigated the effect of the formality in a given context on pitch, I would for sure want "attitude" (the formal/informal condition) as a fixed effect, thereby excluding m4 (f0mn ~ gender + (1 | scenario) + (1 | subject)).

Given that including the interaction is both yielding insignificance and raising the AIC value, I've decided to go with the two-level model that predicts pitch (f0mn) with gender and attitude as fixed effects and subject and scenario as random effects, but including no interaction: f0mn ~ gender + attitude + (1 | scenario) + (1 | subject).

Subject and scenario has been set as random intercepts as I expect different baseline pitch for each participant and different effect on pitch for each scenario. We see that the subject random effect in fact explains quite a substantial part of the total variance, whereas scenario explains a lesser part. 

Results: By setting the alpha level to 5 %, I can conclude that men have a significantly lower pitch (men: 139 Hz) than women (woman: 254 Hz) (p < .05). I can also conclude that in a formal context there was found a significantly lower pitch by 14.8 Hz (p < .05).


```{r}
qqPlot(residuals(m6))
```
The residual qqplot reveals that the residuals are a bit right-skewed, but I would accept it. 

